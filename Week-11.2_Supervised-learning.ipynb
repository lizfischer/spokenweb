{
cells: [
{
cell_type: "markdown",
metadata: { },
source: [
"# *Supervised learning*"
]
},
{
cell_type: "code",
execution_count: null,
metadata: { },
outputs: [ ],
source: [
"%%capture ",
"# Include the line above to hide a cell's text output. ",
" ",
"## Download sample 'sports' and 'world' articles sets, then unzip. ",
" ",
"import os ",
" ",
"os.chdir('/sharedfolder/') ",
" ",
"!wget -N https://github.com/pcda17/pcda17.github.io/raw/master/week/11/nyt_world_11-19-2017.zip ",
"!unzip -o nyt_world_11-19-2017.zip ",
" ",
"!wget -N https://github.com/pcda17/pcda17.github.io/raw/master/week/11/nyt_sports_11-19-2017.zip ",
"!unzip -o nyt_sports_11-19-2017.zip"
]
},
{
cell_type: "code",
execution_count: null,
metadata: { },
outputs: [ ],
source: [
"## Loading 'world' articles as a list of strings ",
" ",
"os.chdir('/sharedfolder/nyt_world_11-19-2017/') ",
" ",
"nyt_world_texts = [] ",
" ",
"for filename in os.listdir('./'): ",
" text_data = open(filename).read().replace('\n', ' ') ",
" nyt_world_texts.append(text_data) ",
" ",
"print(len(nyt_world_texts))"
]
},
{
cell_type: "code",
execution_count: null,
metadata: { },
outputs: [ ],
source: [
"## Loading 'sports' articles as a list of strings ",
" ",
"os.chdir('/sharedfolder/nyt_sports_11-19-2017/') ",
" ",
"nyt_sports_texts = [] ",
" ",
"for filename in os.listdir('./'): ",
" text_data = open(filename).read().replace('\n', ' ') ",
" nyt_sports_texts.append(text_data) ",
" ",
"print(len(nyt_sports_texts))"
]
},
{
cell_type: "code",
execution_count: null,
metadata: { },
outputs: [ ],
source: [
"## Divide articles into training and test sets (reserving 8 articles for test set) ",
" ",
"nyt_world_train = nyt_world_texts[:-8] ",
"nyt_sports_train = nyt_sports_texts[:-8] ",
" ",
"nyt_world_test = nyt_world_texts[-8:] ",
"nyt_sports_test = nyt_sports_texts[-8:] ",
" ",
"print('Training set lengths:') ",
"print(len(nyt_world_train)) ",
"print(len(nyt_sports_train)) ",
" ",
"print() ## empty line ",
" ",
"print('Test set lengths:') ",
"print(len(nyt_world_test)) ",
"print(len(nyt_sports_test))"
]
},
{
cell_type: "code",
execution_count: null,
metadata: { },
outputs: [ ],
source: [
"## Note that the '*' operator can be used to loop a list: ",
" ",
"repeated_list = [0]*5 ",
" ",
"repeated_list"
]
},
{
cell_type: "code",
execution_count: null,
metadata: { },
outputs: [ ],
source: [
"## And we use '+' to concatenate lists: ",
" ",
"repeated_list_2 = [1]*10 + [0]*9 + ['j']*3 ",
" ",
"repeated_list_2"
]
},
{
cell_type: "code",
execution_count: null,
metadata: { },
outputs: [ ],
source: [
"## Combing training data ",
" ",
"combined_texts = nyt_world_train + nyt_sports_train ",
" ",
"## Creating list of associated class values: ",
"## 0 for 'world', 1 for 'sports' ",
" ",
"y = [0]*len(nyt_world_train) + [1]*len(nyt_sports_train)"
]
},
{
cell_type: "code",
execution_count: null,
metadata: { },
outputs: [ ],
source: [
"## Creating vectorized training set using our combined sentence list ",
" ",
"from sklearn.feature_extraction.text import CountVectorizer ",
" ",
"vectorizer = CountVectorizer() ",
" ",
"X = vectorizer.fit_transform(combined_texts) ",
" ",
"X.shape"
]
},
{
cell_type: "code",
execution_count: null,
metadata: { },
outputs: [ ],
source: [ ]
},
{
cell_type: "code",
execution_count: null,
metadata: { },
outputs: [ ],
source: [
"## Training a multinomial naive Bayes classifier ",
"## X is a combined list of 'world' and 'sports' vectors ",
"## y is a list of classes (0 or 1) ",
" ",
"from sklearn.naive_bayes import MultinomialNB ",
" ",
"naive_bayes_classifier = MultinomialNB().fit(X, y)"
]
},
{
cell_type: "code",
execution_count: null,
metadata: { },
outputs: [ ],
source: [
"## Classifying 'world' test set ",
" ",
"input_vector = vectorizer.transform(nyt_world_test) ## Converting a list of string to vector format established above ",
" ",
"naive_bayes_classifier.predict(input_vector) ## Classifying each article in the list. '0' is correct."
]
},
{
cell_type: "code",
execution_count: null,
metadata: { },
outputs: [ ],
source: [
"## Classifying 'sports' test set ",
" ",
"input_vector = vectorizer.transform(nyt_sports_test) ## Converting a list of string to vector format established above ",
" ",
"naive_bayes_classifier.predict(input_vector) ## Classifying each article in the list. '1' is correct. ",
" ",
"## We'll continue using this set of vectors in the cells below."
]
},
{
cell_type: "code",
execution_count: null,
metadata: { },
outputs: [ ],
source: [
"## k-nearest neighbor classifier ",
" ",
"from sklearn.neighbors import KNeighborsClassifier ",
" ",
"knn_classifier = KNeighborsClassifier(n_neighbors=5) ",
" ",
"knn_classifier.fit(X, y) ",
" ",
"knn_classifier.predict(input_vector)"
]
},
{
cell_type: "code",
execution_count: null,
metadata: { },
outputs: [ ],
source: [
"## Logistic Regression classifier ",
" ",
"from sklearn.linear_model import LogisticRegression ",
" ",
"lr_classifier = LogisticRegression() ",
" ",
"lr_classifier.fit(X, y) ",
" ",
"lr_classifier.predict(input_vector)"
]
},
{
cell_type: "code",
execution_count: null,
metadata: { },
outputs: [ ],
source: [
"## Support Vector Machine (SVM) classifer ",
" ",
"from sklearn.svm import SVC ",
" ",
"svm_classifier = SVC(kernel='linear') ",
" ",
"svm_classifier.fit(X, y) ",
" ",
"svm_classifier.predict(input_vector)"
]
},
{
cell_type: "code",
execution_count: null,
metadata: { },
outputs: [ ],
source: [
"## Multi-layer perceptron classifier (a shallow neural network) ",
" ",
"from sklearn.neural_network import MLPClassifier ",
" ",
"mlp_classifier = MLPClassifier() ",
" ",
"mlp_classifier.fit(X, y) ",
" ",
"mlp_classifier.predict(input_vector)"
]
},
{
cell_type: "code",
execution_count: null,
metadata: { },
outputs: [ ],
source: [ ]
},
{
cell_type: "code",
execution_count: null,
metadata: { },
outputs: [ ],
source: [ ]
},
{
cell_type: "markdown",
metadata: { },
source: [
"### *Assignment * ",
" ",
" Write some code that downloads a live New York Times page and classifies it as 'world' or 'sports'."
]
},
{
cell_type: "code",
execution_count: null,
metadata: { },
outputs: [ ],
source: [
"%%capture ",
" ",
"!apt-get -y install libxml2-dev libxslt-dev ",
"!pip3 install newspaper3k"
]
},
{
cell_type: "code",
execution_count: null,
metadata: { },
outputs: [ ],
source: [
"## Using the 'newspaper' package to extract article text ",
" ",
"from newspaper import Article ",
" ",
"def url_to_article_text(url): ",
" article = Article(url) ",
" article.download() ",
" article.parse() ",
" article_text = article.text.replace('\n', ' ') ",
" return article_text"
]
},
{
cell_type: "code",
execution_count: null,
metadata: { },
outputs: [ ],
source: [
"url = 'https://www.nytimes.com/2017/11/19/sports/patriots-beat-raiders-mexico.html' ",
" ",
"article_text = url_to_article_text(url) ",
" ",
"article_text[:2000]"
]
},
{
cell_type: "code",
execution_count: null,
metadata: { },
outputs: [ ],
source: [ ]
},
{
cell_type: "code",
execution_count: null,
metadata: { },
outputs: [ ],
source: [ ]
},
{
cell_type: "code",
execution_count: null,
metadata: { },
outputs: [ ],
source: [ ]
},
{
cell_type: "code",
execution_count: null,
metadata: { },
outputs: [ ],
source: [ ]
},
{
cell_type: "code",
execution_count: null,
metadata: { },
outputs: [ ],
source: [ ]
}
],
metadata: {
kernelspec: {
display_name: "Python 3",
language: "python",
name: "python3"
},
language_info: {
codemirror_mode: {
name: "ipython",
version: 3
},
file_extension: ".py",
mimetype: "text/x-python",
name: "python",
nbconvert_exporter: "python",
pygments_lexer: "ipython3",
version: "3.5.2"
}
},
nbformat: 4,
nbformat_minor: 2
}